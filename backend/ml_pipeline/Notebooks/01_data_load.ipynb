{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cb963e7-9ecb-4af5-b794-60bf139d958e",
   "metadata": {},
   "source": [
    "# SLDCE – Notebook 01: Config-Driven Data Loading\n",
    "### This notebook loads and standardizes any dataset using configuration only.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c61de97-1cad-4acc-b3b4-334b5842e39d",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa80a9d-3220-4bba-877f-7dd6922665a1",
   "metadata": {},
   "source": [
    "## Imports & Project Root\n",
    "✔ Notebook can access src/, config/, data/\n",
    "✔ No fragile ../ path guessing\n",
    "✔ Works for any dataset, any OS\n",
    "✔ Immediately tells you if folder structure is wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7cc0b865-006f-4dda-b880-0f07faf04ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: C:\\Project_Final_Year\n",
      "Config exists: True\n",
      "Raw data exists: True\n"
     ]
    }
   ],
   "source": [
    "# ========== BASIC IMPORTS ==========\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import pandas as pd\n",
    "\n",
    "# ========== ADD PROJECT ROOT TO PATH ==========\n",
    "PROJECT_ROOT = Path(\"..\").resolve()\n",
    "sys.path.append(str(PROJECT_ROOT))\n",
    "\n",
    "# ========== SANITY CHECK ==========\n",
    "print(\"Project root:\", PROJECT_ROOT)\n",
    "print(\"Config exists:\", (PROJECT_ROOT / \"config/default.yaml\").exists())\n",
    "print(\"Raw data exists:\", (PROJECT_ROOT / \"data/raw\").exists())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bd99e1-2c60-4b7f-a661-0a077a01620b",
   "metadata": {},
   "source": [
    "## Load Configuration\n",
    "✔ Loads only from config (no hardcoding)\n",
    "✔ Makes pipeline dataset-agnostic\n",
    "✔ Central control for dataset + target\n",
    "✔ Safe for any future dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c106c067-26e9-4dab-aa8e-3507ae64a552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset path: data/raw/adult.csv\n",
      "Target column: income\n"
     ]
    }
   ],
   "source": [
    "# ========== LOAD CONFIG ==========\n",
    "with open(PROJECT_ROOT / \"config/default.yaml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# ========== READ DATASET CONFIG ==========\n",
    "DATA_PATH = config[\"dataset\"][\"path\"]\n",
    "TARGET = config[\"dataset\"][\"target_column\"]\n",
    "\n",
    "print(\"Dataset path:\", DATA_PATH)\n",
    "print(\"Target column:\", TARGET)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50c0670-b3c2-4e35-afc9-ca9e0068d2b6",
   "metadata": {},
   "source": [
    "## Load Dataset\n",
    "✔ Works for CSV / XLS / XLSX\n",
    "✔ Uses project-root–anchored paths\n",
    "✔ No hardcoded filenames\n",
    "✔ Fails early if file is missing (good!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "daabb0d7-1e07-4fec-9722-2fc931931b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully\n",
      "Shape: (32561, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education.num</th>\n",
       "      <th>marital.status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital.gain</th>\n",
       "      <th>capital.loss</th>\n",
       "      <th>hours.per.week</th>\n",
       "      <th>native.country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90</td>\n",
       "      <td>?</td>\n",
       "      <td>77053</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>?</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>82</td>\n",
       "      <td>Private</td>\n",
       "      <td>132870</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>18</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66</td>\n",
       "      <td>?</td>\n",
       "      <td>186061</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>?</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>4356</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54</td>\n",
       "      <td>Private</td>\n",
       "      <td>140359</td>\n",
       "      <td>7th-8th</td>\n",
       "      <td>4</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>3900</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>Private</td>\n",
       "      <td>264663</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Separated</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>3900</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age workclass  fnlwgt     education  education.num marital.status  \\\n",
       "0   90         ?   77053       HS-grad              9        Widowed   \n",
       "1   82   Private  132870       HS-grad              9        Widowed   \n",
       "2   66         ?  186061  Some-college             10        Widowed   \n",
       "3   54   Private  140359       7th-8th              4       Divorced   \n",
       "4   41   Private  264663  Some-college             10      Separated   \n",
       "\n",
       "          occupation   relationship   race     sex  capital.gain  \\\n",
       "0                  ?  Not-in-family  White  Female             0   \n",
       "1    Exec-managerial  Not-in-family  White  Female             0   \n",
       "2                  ?      Unmarried  Black  Female             0   \n",
       "3  Machine-op-inspct      Unmarried  White  Female             0   \n",
       "4     Prof-specialty      Own-child  White  Female             0   \n",
       "\n",
       "   capital.loss  hours.per.week native.country income  \n",
       "0          4356              40  United-States  <=50K  \n",
       "1          4356              18  United-States  <=50K  \n",
       "2          4356              40  United-States  <=50K  \n",
       "3          3900              40  United-States  <=50K  \n",
       "4          3900              40  United-States  <=50K  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ========== LOAD DATASET ==========\n",
    "from src.data.loader import load_dataset\n",
    "\n",
    "df = load_dataset(PROJECT_ROOT / DATA_PATH)\n",
    "\n",
    "# ========== BASIC VIEW ==========\n",
    "print(\"Dataset loaded successfully\")\n",
    "print(\"Shape:\", df.shape)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517b2ae1-1503-4ea9-baae-1f6c4e8b4ef3",
   "metadata": {},
   "source": [
    "## Dataset Sanity Checks\n",
    "✔ Confirms all column names\n",
    "✔ Detects missing values early\n",
    "✔ Verifies target column correctness\n",
    "✔ Prevents silent bugs later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5bfe1ee5-1614-43b3-9991-f1e6a6b5af27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns:\n",
      "['age', 'workclass', 'fnlwgt', 'education', 'education.num', 'marital.status', 'occupation', 'relationship', 'race', 'sex', 'capital.gain', 'capital.loss', 'hours.per.week', 'native.country', 'income']\n",
      "\n",
      "Missing values per column:\n",
      "age               0\n",
      "workclass         0\n",
      "fnlwgt            0\n",
      "education         0\n",
      "education.num     0\n",
      "marital.status    0\n",
      "occupation        0\n",
      "relationship      0\n",
      "race              0\n",
      "sex               0\n",
      "capital.gain      0\n",
      "capital.loss      0\n",
      "hours.per.week    0\n",
      "native.country    0\n",
      "income            0\n",
      "dtype: int64\n",
      "\n",
      "Target distribution:\n",
      "income\n",
      "<=50K    24720\n",
      ">50K      7841\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ========== BASIC DATASET CHECKS ==========\n",
    "print(\"Columns:\")\n",
    "print(df.columns.tolist())\n",
    "\n",
    "print(\"\\nMissing values per column:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "print(\"\\nTarget distribution:\")\n",
    "print(df[TARGET].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b08d37-126a-40af-a43e-6c293a47b540",
   "metadata": {},
   "source": [
    "## Feature Type Detection\n",
    "✔ Does not assume target type\n",
    "✔ Works for any dataset\n",
    "✔ Safe even if target is categorical\n",
    "✔ No .drop() → no KeyError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0a2b246-a409-4271-b1d9-5578466cc9c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric columns: ['age', 'fnlwgt', 'education.num', 'capital.gain', 'capital.loss', 'hours.per.week']\n",
      "Categorical columns: ['workclass', 'education', 'marital.status', 'occupation', 'relationship', 'race', 'sex', 'native.country']\n"
     ]
    }
   ],
   "source": [
    "# ========== CLEAN COLUMN NAMES ==========\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# ========== IDENTIFY FEATURE TYPES ==========\n",
    "numeric_cols = df.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "categorical_cols = df.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "\n",
    "# ========== REMOVE TARGET SAFELY ==========\n",
    "if TARGET in numeric_cols:\n",
    "    numeric_cols.remove(TARGET)\n",
    "\n",
    "if TARGET in categorical_cols:\n",
    "    categorical_cols.remove(TARGET)\n",
    "\n",
    "print(\"Numeric columns:\", numeric_cols)\n",
    "print(\"Categorical columns:\", categorical_cols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b74ea11-4ba4-43dd-9a24-30cacf3085be",
   "metadata": {},
   "source": [
    "## Preprocessing Pipeline\n",
    "✔ Works for any dataset\n",
    "✔ Handles unseen categories safely\n",
    "✔ No data leakage (fit later, not here)\n",
    "✔ Fully reusable for future datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fba803f2-371b-400a-8d3c-660a15e25c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing pipeline created successfully\n"
     ]
    }
   ],
   "source": [
    "# ========== PREPROCESSING PIPELINE ==========\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "# Numeric features\n",
    "numeric_pipeline = Pipeline(steps=[\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "# Categorical features\n",
    "try:\n",
    "    # sklearn >= 1.2\n",
    "    categorical_pipeline = Pipeline(steps=[\n",
    "        (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
    "    ])\n",
    "except TypeError:\n",
    "    # sklearn < 1.2\n",
    "    categorical_pipeline = Pipeline(steps=[\n",
    "        (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\", sparse=False))\n",
    "    ])\n",
    "\n",
    "# Combine pipelines\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_pipeline, numeric_cols),\n",
    "        (\"cat\", categorical_pipeline, categorical_cols)\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "print(\"Preprocessing pipeline created successfully\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb2ccbf-5119-495a-971d-f9ce9609f88f",
   "metadata": {},
   "source": [
    "## Train / Test Split\n",
    "✔ Stratified split (important for income imbalance)\n",
    "✔ Controlled by config (dataset-agnostic)\n",
    "✔ No preprocessing applied yet (no leakage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f5b4c1a1-55d1-4e52-a53a-a21c1ad55552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: (26048, 14)\n",
      "Test size: (6513, 14)\n"
     ]
    }
   ],
   "source": [
    "# ========== TRAIN / TEST SPLIT ==========\n",
    "from src.data.splitter import split_data\n",
    "\n",
    "X_train, X_test, y_train, y_test = split_data(\n",
    "    df,\n",
    "    TARGET,\n",
    "    test_size=config[\"preprocessing\"][\"test_size\"],\n",
    "    random_state=config[\"preprocessing\"][\"random_state\"]\n",
    ")\n",
    "\n",
    "print(\"Train size:\", X_train.shape)\n",
    "print(\"Test size:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bafbf32-da55-4f7a-975a-8d1a6466481a",
   "metadata": {},
   "source": [
    "## Fit Preprocessor & Save Processed Data\n",
    "✔ Data loaded\n",
    "✔ Config-driven\n",
    "✔ Generic preprocessing\n",
    "✔ Works for any dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd8143ae-0d0d-43b2-823f-889634cf4c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved successfully\n",
      "Train processed shape: (26048, 108)\n",
      "Test processed shape: (6513, 108)\n"
     ]
    }
   ],
   "source": [
    "# ========== FIT PREPROCESSOR ==========\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_test_processed = preprocessor.transform(X_test)\n",
    "\n",
    "# ========== CONVERT TO DATAFRAME ==========\n",
    "train_df = pd.DataFrame(X_train_processed)\n",
    "train_df[\"label\"] = y_train.values\n",
    "\n",
    "test_df = pd.DataFrame(X_test_processed)\n",
    "test_df[\"label\"] = y_test.values\n",
    "\n",
    "# ========== SAVE PROCESSED DATA ==========\n",
    "processed_path = PROJECT_ROOT / \"data/processed\"\n",
    "processed_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "train_df.to_csv(processed_path / \"dataset_processed_train.csv\", index=False)\n",
    "test_df.to_csv(processed_path / \"dataset_processed_test.csv\", index=False)\n",
    "\n",
    "print(\"Processed data saved successfully\")\n",
    "print(\"Train processed shape:\", train_df.shape)\n",
    "print(\"Test processed shape:\", test_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13266327-e1e2-4e29-8bcf-6b16f37798bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (final_year_env)",
   "language": "python",
   "name": "final_year_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
